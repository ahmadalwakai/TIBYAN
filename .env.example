# ===========================================
# Tibyan LMS - Environment Variables
# ===========================================
# Copy this file to .env and fill in your values
# See VERCEL_DEPLOYMENT.md for production setup

# ===========================================
# DATABASE (Required)
# ===========================================
# PostgreSQL connection string - Use Vercel Postgres, Neon, Supabase, etc.
DATABASE_URL="postgresql://user:password@host:5432/tibyan?sslmode=require"

# Direct database URL (for Prisma migrations in serverless environments)
DIRECT_DATABASE_URL="postgresql://user:password@host:5432/tibyan?sslmode=require"

# ===========================================
# AUTHENTICATION (Required for production)
# ===========================================
# JWT secret for custom auth (NOT NextAuth - this app uses custom JWT cookies)
# Generate with: openssl rand -hex 32
JWT_SECRET="your-64-character-hex-secret-here"

# ===========================================
# APPLICATION
# ===========================================
NEXT_PUBLIC_APP_URL="https://your-domain.vercel.app"
NEXT_PUBLIC_APP_NAME="تبيان"

# ===========================================
# EMAIL SERVICE (Required for auth emails)
# ===========================================
# Get your API key from https://resend.com
RESEND_API_KEY="re_xxxxxxxxxxxxxxxxxxxxxxxxxxxx"
FROM_EMAIL="noreply@your-domain.com"

# ===========================================
# LLM / AI AGENT CONFIGURATION
# ===========================================
# Provider is determined by GROQ_API_KEY presence:
# - If GROQ_API_KEY is set: always uses Groq (remote)
# - If GROQ_API_KEY is missing in production: throws error
# - If GROQ_API_KEY is missing in dev: falls back to mock

# --- Groq API (Required for production) ---
# Get your API key from https://console.groq.com
GROQ_API_KEY=

# --- LLM Settings ---
LLM_PROVIDER=remote
REMOTE_LLM_BASE_URL=https://api.groq.com/openai/v1
REMOTE_LLM_MODEL=llama-3.3-70b-versatile
# --- LLM Settings ---
LLM_PROVIDER=remote
REMOTE_LLM_BASE_URL=https://api.groq.com/openai/v1
REMOTE_LLM_MODEL=llama-3.3-70b-versatile
LLM_TIMEOUT_MS=120000
LLM_STREAMING_ENABLED=true

# ===========================================
# OPTIONAL: ANALYTICS & MONITORING
# ===========================================
# SENTRY_DSN="https://xxx@sentry.io/xxx"
# NEXT_PUBLIC_GOOGLE_ANALYTICS="G-XXXXXXXXXX"

# ===========================================
# OPTIONAL: FILE STORAGE
# ===========================================
# BLOB_READ_WRITE_TOKEN="vercel_blob_xxx"
# CLOUDINARY_CLOUD_NAME="your-cloud-name"
# CLOUDINARY_API_KEY="xxx"
# CLOUDINARY_API_SECRET="xxx"

# ===========================================
# OPTIONAL: REDIS (caching/sessions)
# ===========================================
# REDIS_URL="redis://default:xxx@xxx.upstash.io:6379"

# ===========================================
# OPTIONAL: PAYMENTS
# ===========================================
# STRIPE_SECRET_KEY="sk_live_xxx"
# STRIPE_WEBHOOK_SECRET="whsec_xxx"
# NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY="pk_live_xxx"

# ===========================================
# DEBUG (Development only)
# ===========================================
# DEBUG_AI="true"
